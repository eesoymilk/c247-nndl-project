optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
lr_scheduler:
  scheduler:
    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR
    warmup_epochs: 10
    max_epochs: 100
    warmup_start_lr: 1.0e-08
    eta_min: 1.0e-06
  interval: epoch
num_filters:
- 128
- 128
- 128
- 256
kernel_size: 32
dilation_base: 3
