\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024


\usepackage[final]{neurips_2024}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}       % figures
\usepackage{enumitem}       % enumerate
\usepackage{caption}
\usepackage{subcaption}


\title{C247 Nerual Nework and Deep Learning\\Project Writeup}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Yu-Wei Chang, Leyi Zou \\
  Department of Electrical and Computer Engineering\\
  University of California, Los Angeles\\
  Los Angeles, CA 90095 \\
  \texttt{\{ywchang,zelozou\}@ucla.edu} \\
}


\begin{document}


\maketitle


\begin{abstract}
    We explore neural network architectures for decoding keystrokes from surface electromyography (sEMG) signals. Specifically, we evaluate four architectures: the baseline TDSConv model, a purely convolutional Temporal Convolutional Network (TCN), a purely recurrent model (LSTM-GRU), and a hybrid architecture combining TCN with LSTM-GRU layers. Our experiments, conducted on a single-user dataset, show that the baseline TDSConv model outperforms alternative architectures, demonstrating robustness and consistent performance. The recurrent-based architectures capture temporal dependencies effectively but exhibit slower convergence and vulnerability to overfitting due to limited data. The TCN model converged quickly but suffered from significant overfitting. These findings highlight the importance of temporal modeling and dataset diversity, motivating further investigation using multi-user datasets and advanced regularization techniques.
\end{abstract}

\input{sections/introduction.tex}

\input{sections/methods.tex}

\input{sections/results.tex}

\input{sections/discussion.tex}

\input{references.tex}

% \input{template_guide.tex}
%
% \input{paper_checklist.tex}

\end{document}
