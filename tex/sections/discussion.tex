\section{Discussion}

\subsubsection{Model Architecture}
An important context for the results is that the data used was from a single user, so the data volume and diversity are limited. The validation and test loss of the hybrid and LSTM-GRU models are significantly lower than those of the other models, while the TCN model has the highest loss. This may suggest that the TCN model is poorly suited for this task. For sEMG, which may require capturing signals with long-term dependencies or strong individual differences, more convolutional layers or more sophisticated parameter adjustments may be required. The TCN model converges too quickly, which may indicate that it is overfitting the training data. On the other hand, the hybrid model and LSTM-GRU model are better at capturing the temporal dependencies in the data. However, because our dataset is limited to a single user, models like the hybrid model may not fully utilize their potential. Multi-user datasets could better exploit the advantages of these models, but they would also increase the challenge of generalization.

Another observation is that the hybrid model took longer to converge than the baseline model. This may be due to the complexity of the hybrid model, and it also suggests that the hybrid model is more prone to overfitting.

\subsubsection{Preprocessing Techniques}
The results of our experiments showed that the model using the 50 Hz notch filter achieved a validation CER that was 8.2\% lower than the baseline model at Epoch 50. This may indicate that removing power line interference is crucial for processing sEMG signals. After removing the 50 Hz interference, the model can focus more on the effective frequency components in the signal, thereby extracting more meaningful features and improving the final performance.

Adaptive Gaussian noise and z-score normalization did not significantly surpass the baseline in the final CER (22.13 and 22.37, respectively, close to the baseline's 20.98), but they performed significantly better than the baseline model in the early stages of training. This may be because normalization and noise addition reduce the model's sensitivity to the scale and distribution of the input data in the early stages, allowing the network to learn the main patterns in the signal faster, thus accelerating convergence. However, in the later stages, the advantages of these preprocessing methods may be balanced by other factors, resulting in final performance that is close to the baseline.

When two bandpass filters with different cutoff frequencies (20 Hz–500 Hz and 20 Hz–150 Hz) were used, the model had very high CER at the beginning of training and poor overall performance. This may indicate that the bandpass filter failed to retain enough of the effective signal components, or there were side effects in the filter design that resulted in the loss of useful information. The much lower CER of these models can be attributed to the bandpass filters suppressing noise, but they may have also weakened some important detailed features that help the model learn. The hyperparameters of the bandpass filter for this task need further optimization to achieve better performance.

From the results, it is evident that the preprocessing techniques can help the model converge faster to some extent. This also suggests that appropriate preprocessing techniques can play an important role in improving learning efficiency.