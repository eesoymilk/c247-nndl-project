\subsection{Architectures}

Surface electromyography (sEMG) signals provide a noninvasive means of detecting muscle activity in the forearms and wrists. However, sEMG data can be both noisy and highly variable across different recording sessions, electrodes, and users. This variability poses a challenge for sequence-level tasks such as keystroke decoding, in which the goal is to accurately predict typed characters from continuous muscle activity signals. To address these challenges, we explore four architectural paradigms, each designed to handle different aspects of the sEMG decoding problem.

The first one is the baseline structure by Hannun et al. (2019). It leverages Time-Depth Separable (TDS) convolutions to capture local temporal features while keeping the parameter footprint small. A short multi-layer perceptron (MLP) is also included to handle electrode shifts in a rotation-invariant manner. Although this approach has shown promise in prior work, it may not fully capture longer-range dependencies or complex spatial-temporal patterns in sEMG data.

The second structure is a convolutional networks tailored to time-series—often referred to as Temporal Convolutional Networks—enable flexible receptive fields through dilations, potentially modeling a wide range of time scales without explicit recurrent gating. By applying rotation-invariant convolutions across electrode channels, the TCN aims to address local, shift-related variability while exploring multiple scales in the time dimension.

Thirdly, purely recurrent designs (e.g., LSTM or GRU stacks) remain a key method for sequence modeling in speech, EEG, and now sEMG contexts, given their ability to learn long-term temporal dependencies. We employ a multi-band approach that processes each sEMG band independently, flattening the spectral-electrode features at each time step and passing them through LSTM and GRU layers in sequence. This design removes all convolutional blocks, thus providing an alternative baseline for purely RNN-based feature extraction.

Finally, we combine the strengths of dilated convolutions (fast, parallelizable extraction of local time patterns) with recurrent gating (robust modeling of long-range dependencies). A TCN front end handles initial band-wise, rotation-invariant feature extraction; the resulting timewise features are then processed by LSTM and GRU layers to refine the global temporal context.

All four architectures feed their per-timestep logits into a CTC loss, which aligns predictions to unlabeled time steps and enables end-to-end training. By comparing these approaches, we seek to identify which combination of local convolutional or global recurrent modeling best suits the inherently noisy and user-dependent nature of sEMG data for keystroke decoding.
